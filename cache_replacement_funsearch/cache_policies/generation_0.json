{
  "generations": [
    [
      "pc_boldest",
      "adaptive_reuse",
      "adaptive_phoenix",
      "pc_lru",
      "lru_aura"
    ]
  ],
  "policies": {
    "lru_reference": {
      "name": "lru_reference",
      "code": "\n#include \"lru_reference.h\"\n\n#include <algorithm>\n#include <cassert>\n\nlru_reference::lru_reference(CACHE* cache) : lru_reference(cache, cache->NUM_SET, cache->NUM_WAY) {}\n\nlru_reference::lru_reference(CACHE* cache, long sets, long ways) : replacement(cache), NUM_WAY(ways), last_used_cycles(static_cast<std::size_t>(sets * ways), 0) {}\n\nlong lru_reference::find_victim(uint32_t triggering_cpu, uint64_t instr_id, long set, const champsim::cache_block* current_set, champsim::address ip,\n                      champsim::address full_addr, access_type type)\n{\n  auto begin = std::next(std::begin(last_used_cycles), set * NUM_WAY);\n  auto end = std::next(begin, NUM_WAY);\n\n  // Find the way whose last use cycle is most distant\n  auto victim = std::min_element(begin, end);\n  assert(begin <= victim);\n  assert(victim < end);\n  return std::distance(begin, victim);\n}\n\nvoid lru_reference::replacement_cache_fill(uint32_t triggering_cpu, long set, long way, champsim::address full_addr, champsim::address ip, champsim::address victim_addr,\n                                 access_type type)\n{\n  // Mark the way as being used on the current cycle\n  last_used_cycles.at((std::size_t)(set * NUM_WAY + way)) = cycle++;\n}\n\nvoid lru_reference::update_replacement_state(uint32_t triggering_cpu, long set, long way, champsim::address full_addr, champsim::address ip,\n                                   champsim::address victim_addr, access_type type, uint8_t hit)\n{\n  // Mark the way as being used on the current cycle\n  if (hit && access_type{type} != access_type::WRITE) // Skip this for writeback hits\n    last_used_cycles.at((std::size_t)(set * NUM_WAY + way)) = cycle++;\n}\n",
      "fitness": -3148.93483,
      "parent_policies": [],
      "compilation_success": true,
      "metrics": {
        "avg_mpki": 3149.0,
        "avg_ipc": 0.6517,
        "traces": {
          "astar_163B.trace.xz": {
            "mpki": 3149,
            "ipc": 0.6517
          }
        }
      }
    },
    "pc_boldest": {
      "name": "pc_boldest",
      "code": "#include \"pc_boldest.h\"\n#include <algorithm>\n#include <cassert>\n#include <tuple>\n\npc_boldest::pc_boldest(CACHE* cache) : pc_boldest(cache, cache->NUM_SET, cache->NUM_WAY) {}\n\npc_boldest::pc_boldest(CACHE* cache, long sets, long ways) : replacement(cache), NUM_WAY(ways), \n  pc_usage(sets, std::vector<uint64_t>(ways, 0)),\n  temporal_boldness(sets, std::vector<uint64_t>(ways, 0)),\n  spatial_boldness(sets, std::vector<uint64_t>(ways, 0))\n{\n}\n\nlong pc_boldest::find_victim(uint32_t triggering_cpu, uint64_t instr_id, long set, const champsim::cache_block* current_set, champsim::address ip,\n                      champsim::address full_addr, access_type type)\n{\n  auto pc = ip.get_pc();\n  \n  // Calculate victim score based on PC usage, temporal boldness, and spatial boldness\n  auto begin = std::next(std::begin(pc_usage), set * NUM_WAY);\n  auto end = std::next(begin, NUM_WAY);\n  \n  // Combine metrics to find the least useful block\n  auto victim = std::min_element(begin, end, \n    [=](const std::tuple<uint64_t, uint64_t, uint64_t>& a, const std::tuple<uint64_t, uint64_t, uint64_t>& b) {\n      return (std::get<0>(a) + std::get<1>(a) + std::get<2>(a)) < \n             (std::get<0>(b) + std::get<1>(b) + std::get<2>(b));\n    });\n  \n  assert(begin <= victim);\n  assert(victim < end);\n  return std::distance(begin, victim);\n}\n\nvoid pc_boldest::replacement_cache_fill(uint32_t triggering_cpu, long set, long way, champsim::address full_addr, champsim::address ip,\n                                 champsim::address victim_addr, access_type type)\n{\n  auto pc = ip.get_pc();\n  pc_usage.at(set * NUM_WAY + way) = cycle++;\n}\n\nvoid pc_boldest::update_replacement_state(uint32_t triggering_cpu, long set, long way, champsim::address full_addr, champsim::address ip,\n                                   champsim::address victim_addr, access_type type, uint8_t hit)\n{\n  if (hit && access_type{type} != access_type::WRITE) {\n    auto pc = ip.get_pc();\n    \n    // Update temporal boldness based on recency\n    temporal_boldness[set][way] = (cycle - temporal_boldness[set][way] < TEMPORAL_THRESHOLD) ? \n                                temporal_boldness[set][way] + 1 : 0;\n    \n    // Update spatial boldness based on PC proximity\n    spatial_boldness[set][way] = (pc.get_offset() - spatial_boldness[set][way]) < 0x100 ? \n                                spatial_boldness[set][way] + 1 : 0;\n    \n    // Update PC usage\n    pc_usage[set][way] = cycle++;\n  }\n}\n",
      "fitness": null,
      "parent_policies": [],
      "compilation_success": false,
      "metrics": {}
    },
    "adaptive_reuse": {
      "name": "adaptive_reuse",
      "code": "#include \"adaptive_reuse.h\"\n\n#include <vector>\n#include <algorithm>\n#include <cassert>\n\nadaptive_reuse::adaptive_reuse(CACHE* cache) : adaptive_reuse(cache, cache->NUM_SET, cache->NUM_WAY) {}\n\nadaptive_reuse::adaptive_reuse(CACHE* cache, long sets, long ways) : replacement(cache), NUM_WAY(ways),\n  last_used_cycles(static_cast<std::size_t>(sets * ways), 0),\n  frequency(static_cast<std::size_t>(sets * ways), 0),\n  pc_histogram(static_cast<std::size_t>(sets * ways), 0),\n  utility_score(static_cast<std::size_t>(sets * ways), 0),\n  backup_way(static_cast<std::size_t>(sets), -1) {}\n\nlong adaptive_reuse::find_victim(uint32_t triggering_cpu, uint64_t instr_id, long set, const champsim::cache_block* current_set,\n                                champsim::address ip, champsim::address full_addr, access_type type) {\n  const auto begin = std::next(std::begin(utility_score), set * NUM_WAY);\n  const auto end = std::next(begin, NUM_WAY);\n\n  // Calculate utility scores for each way in the set\n  for (auto it = begin; it != end; ++it) {\n    const auto index = std::distance(std::begin(utility_score), it);\n    const auto recency = cycle - last_used_cycles[index];\n    const auto inv_recency = static_cast<double>(recency) * 0.1; // Inverse relation\n    const auto inv_frequency = static_cast<double>(1.0 / (frequency[index] + 1));\n    const auto pc_weight = static_cast<double>(1.0 / (pc_histogram[index] + 1));\n    *it = static_cast<uint64_t>(inv_recency + inv_frequency + pc_weight);\n  }\n\n  const auto victim = std::min_element(begin, end);\n  assert(begin <= victim);\n  assert(victim < end);\n  return std::distance(begin, victim);\n}\n\nvoid adaptive_reuse::replacement_cache_fill(uint32_t triggering_cpu, long set, long way,\n                                            champsim::address full_addr, champsim::address ip,\n                                            champsim::address victim_addr, access_type type) {\n  const auto index = static_cast<std::size_t>(set * NUM_WAY + way);\n  last_used_cycles[index] = cycle++;\n  frequency[index]++;\n  pc_histogram[index]++;\n  utility_score[index] = 0; // Reset utility score\n}\n\nvoid adaptive_reuse::update_replacement_state(uint32_t triggering_cpu, long set, long way,\n                                             champsim::address full_addr, champsim::address ip,\n                                             champsim::address victim_addr, access_type type, uint8_t hit) {\n  if (hit && access_type{type} != access_type::WRITE) { // Skip for writeback hits\n    const auto index = static_cast<std::size_t>(set * NUM_WAY + way);\n    last_used_cycles[index] = cycle++;\n    frequency[index]++;\n    pc_histogram[index]++;\n    utility_score[index] = 0; // Reset utility score\n  }\n}\n",
      "fitness": -3148.93483,
      "parent_policies": [],
      "compilation_success": true,
      "metrics": {
        "avg_mpki": 3149.0,
        "avg_ipc": 0.6517,
        "traces": {
          "astar_163B.trace.xz": {
            "mpki": 3149,
            "ipc": 0.6517
          }
        }
      }
    },
    "adaptive_phoenix": {
      "name": "adaptive_phoenix",
      "code": "#include \"adaptive_phoenix.h\"\n#include <algorithm>\n#include <cassert>\n\nadaptive_phoenix::adaptive_phoenix(CACHE* cache) : adaptive_phoenix(cache, cache->NUM_SET, cache->NUM_WAY) {}\n\nadaptive_phoenix::adaptive_phoenix(CACHE* cache, long sets, long ways) : \n    replacement(cache), \n    NUM_WAY(ways), \n    last_used_cycles(static_cast<std::size_t>(sets * ways), 0),\n    pc_history(static_cast<std::size_t>(sets * ways), 0),\n    access_pattern(static_cast<std::size_t>(sets * ways), 0),\n    bypass_candidate(static_cast<std::size_t>(sets * ways), false),\n    victim_cache(static_cast<std::size_t>(sets), 0),\n    set_conflicts(static_cast<std::size_t>(sets), 0) \n{\n    // Initialize victim cache with invalid addresses\n    std::fill(victim_cache.begin(), victim_cache.end(), (uint64_t)-1);\n}\n\nlong adaptive_phoenix::find_victim(uint32_t triggering_cpu, uint64_t instr_id, long set, const champsim::cache_block* current_set,\n                          champsim::address ip, champsim::address full_addr, access_type type)\n{\n    // Calculate start and end indices for the current set\n    auto begin = std::next(std::begin(last_used_cycles), set * NUM_WAY);\n    auto end = std::next(begin, NUM_WAY);\n    \n    // Find the best victim candidate based on multiple criteria\n    long victim_way = -1;\n    uint64_t max_score = 0;\n    \n    // Iterate through each way in the set\n    for (long way = 0; way < NUM_WAY; ++way) {\n        auto idx = begin + way;\n        \n        // Calculate the score based on:\n        // 1. Recency of use (lower cycle is better)\n        // 2. PC distance (if same PC, higher priority)\n        // 3. Access pattern (sequential vs random)\n        // 4. Bypass candidate status\n        uint64_t score = last_used_cycles[idx];\n        \n        // Apply PC-based promotion if same program counter\n        if (pc_history[idx] == ip) {\n            score = std::max(score, cycle); // Promote to most recently used\n        }\n        \n        // Demote blocks with sequential access patterns\n        if (access_pattern[idx] == access_type::READ && \n            (instr_id - pc_history[idx]) > 32) {\n            score = std::min(score, 0); // Demote if sequential access\n        }\n        \n        // Bypass low-utility blocks\n        if (bypass_candidate[idx]) {\n            score = std::max(score, cycle); // Prioritize bypass candidates\n        }\n        \n        // Track victim blocks in victim cache\n        if (score > max_score) {\n            max_score = score;\n            victim_way = way;\n        }\n    }\n    \n    // Update victim cache with evicted blocks\n    if (victim_way != -1) {\n        victim_cache[set] = current_set[victim_way].address;\n    }\n    \n    return victim_way;\n}\n\nvoid adaptive_phoenix::replacement_cache_fill(uint32_t triggering_cpu, long set, long way, \n                                  champsim::address full_addr, champsim::address ip,\n                                  champsim::address victim_addr, access_type type)\n{\n    // Update metadata for the filled block\n    auto idx = static_cast<std::size_t>(set * NUM_WAY + way);\n    last_used_cycles[idx] = cycle++;\n    pc_history[idx] = ip;\n    access_pattern[idx] = static_cast<uint64_t>(type);\n    bypass_candidate[idx] = false;\n}\n\nvoid adaptive_phoenix::update_replacement_state(uint32_t triggering_cpu, long set, long way,\n                                      champsim::address full_addr, champsim::address ip,\n                                      champsim::address victim_addr, access_type type,\n                                      uint8_t hit)\n{\n    if (hit && type != access_type::WRITE) {\n        auto idx = static_cast<std::size_t>(set * NUM_WAY + way);\n        last_used_cycles[idx] = cycle++;\n        pc_history[idx] = ip;\n        \n        // Detect sequential patterns\n        if (type == access_type::READ && \n            (instr_id - pc_history[idx]) <= 32) {\n            access_pattern[idx] = access_type::SEQUENTIAL;\n        }\n        \n        // Detect write-once patterns\n        if (type == access_type::WRITE && \n            !is_write_once(set, way)) {\n            bypass_candidate[idx] = true;\n        }\n    }\n}\n\nbool adaptive_phoenix::is_write_once(long set, long way) const {\n    auto idx = static_cast<std::size_t>(set * NUM_WAY + way);\n    return pc_history[idx] == 0 || \n           (access_pattern[idx] == access_type::WRITE && \n            (cycle - last_used_cycles[idx]) > 1000);\n}\n",
      "fitness": null,
      "parent_policies": [],
      "compilation_success": false,
      "metrics": {}
    },
    "pc_lru": {
      "name": "pc_lru",
      "code": "#include \"pc_lru.h\"\n#include <algorithm>\n#include <assert.h>\n\npc_lru::pc_lru(CACHE* cache) : pc_lru(cache, cache->NUM_SET, cache->NUM_WAY) {}\n\npc_lru::pc_lru(CACHE* cache, long sets, long ways) : replacement(cache), NUM_WAY(ways) {\n    block_metadata.resize(static_cast<std::size_t>(sets * ways), {0, {}, 0});\n}\n\nlong pc_lru::find_victim(uint32_t triggering_cpu, uint64_t instr_id, long set, const champsim::cache_block* current_set,\n                        champsim::address ip, champsim::address full_addr, access_type type)\n{\n    const auto begin = block_metadata.begin() + (set * NUM_WAY);\n    const auto end = begin + NUM_WAY;\n    const uint64_t current_pc = ip.pcie();  // Get program counter\n\n    long victim_way = -1;\n    uint64_t min_utility = MAX_UTILITY;\n\n    // Find victim based on utility score and PC history\n    for (long way = 0; way < NUM_WAY; ++way) {\n        auto& meta = begin[way];\n        \n        // Calculate PC delta from previous accesses\n        uint64_t pc_delta = 0;\n        if (meta.pc_history[0] != 0) {\n            pc_delta = current_pc - meta.pc_history[0];\n        }\n\n        // Prefer victims with:\n        // 1. Low utility score\n        // 2. High PC delta (indicating temporal distance)\n        // 3. PC delta above threshold (likely to be non-reused)\n        if (meta.utility_score < min_utility ||\n            (pc_delta > PC_DELTA_THRESHOLD && meta.utility_score < MAX_UTILITY)) {\n            min_utility = meta.utility_score;\n            victim_way = way;\n        }\n\n        // If we find a block with PC delta above threshold, prefer it as victim\n        if (pc_delta > PC_DELTA_THRESHOLD) {\n            victim_way = way;\n            break;\n        }\n    }\n\n    // If no victim found with PC delta above threshold, fall back to LRU\n    if (victim_way == -1) {\n        auto victim = std::min_element(begin, end, [](const CacheBlockMetadata& a, const CacheBlockMetadata& b) {\n            return a.last_used_cycle < b.last_used_cycle;\n        });\n        victim_way = std::distance(begin, victim);\n    }\n\n    return victim_way;\n}\n\nvoid pc_lru::replacement_cache_fill(uint32_t triggering_cpu, long set, long way, champsim::address full_addr,\n                                    champsim::address ip, champsim::address victim_addr, access_type type)\n{\n    auto& meta = block_metadata.at(static_cast<std::size_t>(set * NUM_WAY + way));\n    meta.last_used_cycle = cycle++;\n    meta.pc_history[0] = ip.pcie();  // Store current PC\n\n    // Update utility score based on PC history\n    for (int i = 7; i > 0; --i) {\n        meta.pc_history[i] = meta.pc_history[i-1];\n    }\n    \n    // Calculate PC delta from previous access\n    uint64_t pc_delta = 0;\n    if (meta.pc_history[1] != 0) {\n        pc_delta = meta.pc_history[0] - meta.pc_history[1];\n    }\n\n    // Adjust utility score based on PC delta\n    meta.utility_score = std::min(MAX_UTILITY, meta.utility_score + pc_delta / 10);\n}\n\nvoid pc_lru::update_replacement_state(uint32_t triggering_cpu, long set, long way, champsim::address full_addr,\n                                     champsim::address ip, champsim::address victim_addr, access_type type,\n                                     uint8_t hit)\n{\n    if (hit && access_type{type} != access_type::WRITE) {  // Skip for writeback hits\n        auto& meta = block_metadata.at(static_cast<std::size_t>(set * NUM_WAY + way));\n        meta.last_used_cycle = cycle++;\n\n        // Update PC history and utility score on hit\n        meta.pc_history[0] = ip.pcie();\n        for (int i = 7; i > 0; --i) {\n            meta.pc_history[i] = meta.pc_history[i-1];\n        }\n\n        // Calculate PC delta\n        uint64_t pc_delta = 0;\n        if (meta.pc_history[1] != 0) {\n            pc_delta = meta.pc_history[0] - meta.pc_history[1];\n        }\n\n        // Adjust utility score based on PC delta\n        meta.utility_score = std::min(MAX_UTILITY, meta.utility_score + pc_delta / 10);\n    }\n}\n",
      "fitness": null,
      "parent_policies": [],
      "compilation_success": false,
      "metrics": {}
    },
    "lru_aura": {
      "name": "lru_aura",
      "code": "#include \"lru_aura.h\"\n#include <algorithm>\n#include <cassert>\n#include <map>\n\nusing namespace champsim::modules::replacement;\n\nlru_aura::lru_aura(CACHE* cache) : lru_aura(cache, cache->NUM_SET, cache->NUM_WAY) {}\n\nlru_aura::lru_aura(CACHE* cache, long sets, long ways) : replacement(cache), NUM_WAY(ways)\n{\n    // Initialize metadata for all cache blocks\n    metadata.resize(sets * ways);\n    for (auto& block : metadata) {\n        block.last_used_cycle = 0;\n        block.access_count = 0;\n    }\n}\n\nlong lru_aura::find_victim(uint32_t triggering_cpu, uint64_t instr_id, long set, const champsim::cache_block* current_set,\n                   champsim::address ip, champsim::address full_addr, access_type type)\n{\n    const auto begin = std::next(std::begin(metadata), set * NUM_WAY);\n    const auto end = std::next(begin, NUM_WAY);\n    \n    // Find the best victim block using Aura's multi-criteria selection\n    auto victim = begin;\n    uint64_t max_score = 0;\n    \n    // Evaluate each block's potential as a victim candidate\n    for (auto it = begin; it < end; ++it) {\n        // Calculate a score based on inverse of various factors\n        uint64_t score = 0;\n        \n        // Prefer blocks with older last_used_cycle (temporal locality)\n        score += cycle - it->last_used_cycle;\n        \n        // Prefer blocks with lower access frequency (temporal stability)\n        score += (cycle / it->access_count) * 2;  // Weight frequency more heavily\n        \n        // Prefer blocks not associated with recent program counters\n        score += it->pc_access_count[ip] << 1;    // Weight PC history\n        \n        // Update victim if current block has higher score\n        if (score > max_score) {\n            max_score = score;\n            victim = it;\n        }\n    }\n    \n    // Calculate the victim way within the set\n    return std::distance(begin, victim);\n}\n\nvoid lru_aura::replacement_cache_fill(uint32_t triggering_cpu, long set, long way, champsim::address full_addr,\n                             champsim::address ip, champsim::address victim_addr, access_type type)\n{\n    const auto block_idx = set * NUM_WAY + way;\n    auto& block = metadata[block_idx];\n    \n    // Update metadata when a new block is inserted\n    block.last_used_cycle = cycle++;\n    block.access_count++;\n    \n    // Track program counter access patterns\n    block.pc_access_count[ip] = cycle++;\n}\n\nvoid lru_aura::update_replacement_state(uint32_t triggering_cpu, long set, long way, champsim::address full_addr,\n                               champsim::address ip, champsim::address victim_addr, access_type type, uint8_t hit)\n{\n    if (hit && type != access_type::WRITE) {  // Skip for writeback hits\n        const auto block_idx = set * NUM_WAY + way;\n        auto& block = metadata[block_idx];\n        \n        // Update metadata on cache hit\n        block.last_used_cycle = cycle++;\n        block.access_count++;\n        block.pc_access_count[ip] = cycle++;\n    }\n}\n",
      "fitness": null,
      "parent_policies": [],
      "compilation_success": false,
      "metrics": {}
    }
  }
}